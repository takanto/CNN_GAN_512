{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN GAN 512 image Notebook.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPam/4ZyspVA4HWG0cVe7Rw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/takanto/CNN_GAN_512/blob/main/CNN_GAN_512_image_Notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **CNN GAN for 512 pixels**"
      ],
      "metadata": {
        "id": "tBtEi32ZBwhn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This GAN model is traditional CNN GAN for 512 pixels. This model is not trained so that GAN can generate any kind of images depending on your input training data. Thus, user needs to train the model by first preparing roughly 50,000 images with (512, 512). When training, please not forget to run with TPU to speed up the training process, and divide training into multiple times if necessary. (When dividing the training, it is recommended that you keep track of epochs by adding number of epochs to the names of the model you save) "
      ],
      "metadata": {
        "id": "5uBxAbluCCWy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Code**"
      ],
      "metadata": {
        "id": "deCTmOrGDCVJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Preparation**"
      ],
      "metadata": {
        "id": "VzNZWy6RJOmj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run the code below before any operation."
      ],
      "metadata": {
        "id": "6SVrrG9FFBRD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "・Import necessary libraries"
      ],
      "metadata": {
        "id": "Uoduz5RaF7Nt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_8wjMqdCBpkj"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import sys, os\n",
        "\n",
        "from tensorflow.keras.layers import Input, Dense, Flatten, Conv2DTranspose, MaxPooling2D, Dropout, BatchNormalization, Reshape, LeakyReLU, Conv2D\n",
        "from tensorflow.keras.applications.vgg16 import VGG16 as PretrainedModel, preprocess_input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing import image"
      ],
      "metadata": {
        "id": "V7R1lGHWBr3g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "・ Setting up TPU environment"
      ],
      "metadata": {
        "id": "CyArr0W0GI-R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu=\"\")\n",
        "tf.config.experimental_connect_to_cluster(resolver)\n",
        "tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "print(\"all devices:\", tf.config.list_logical_devices(\"TPU\"))"
      ],
      "metadata": {
        "id": "zKviUhcTDH1y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "strategy = tf.distribute.TPUStrategy(resolver)"
      ],
      "metadata": {
        "id": "-1d8wfQYDKqw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "・ Loading your training data. Please upload your training images. Format needs to be 512 pixels. "
      ],
      "metadata": {
        "id": "kj_FoUDuGOHW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import os, numpy as np\n",
        "folder = 'name of your file containing training images'\n",
        "\n",
        "read = lambda imname: np.asarray(Image.open(imname).convert(\"RGB\"))\n",
        "\n",
        "ims = [read(os.path.join(folder, filename)) for filename in os.listdir(folder)]\n",
        "im_array = np.array(ims, dtype='uint8')\n",
        "im_array = (im_array / 255.0)*2 - 1"
      ],
      "metadata": {
        "id": "BmOEm-0qDNJK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "・　This function create plot of 25 images generated by generator through training."
      ],
      "metadata": {
        "id": "L8Wy8Ny-LDF6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sample_images(epoch):\n",
        "  rows, cols = 5, 5\n",
        "  noise = np.random.randn(rows*cols, latent_dim)\n",
        "  imgs = generator.predict(noise)\n",
        "\n",
        "  # rescaling image from -1 to 1 to 0 to 1\n",
        "  imgs = imgs * 0.5 + 0.5\n",
        "\n",
        "  fig, axs = plt.subplots(rows, cols)\n",
        "  idx = 0\n",
        "  for i in range(rows):\n",
        "    for j in range(cols):\n",
        "      axs[i,j].imshow(imgs[idx].reshape(512,512,3))\n",
        "      axs[i,j].axis(\"off\")\n",
        "      idx += 1\n",
        "  fig.savefig(\"cifar_gan_images/%d.png\" % epoch)\n",
        "  plt.close()"
      ],
      "metadata": {
        "id": "RUozrZXmK-uj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **First time running**"
      ],
      "metadata": {
        "id": "TsNqrQvFJK_a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run below when it is first time for you to train your model."
      ],
      "metadata": {
        "id": "siKvbw3JJZLq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "・ Define generator. It uses convolutional transpose layer for upsampling. "
      ],
      "metadata": {
        "id": "Ux3LawzCGcaj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "atent_dim = 100\n",
        "def build_generator(latent_dim):\n",
        "  \n",
        "  i = Input(shape=(latent_dim,))\n",
        "  x = Dense(256*4*4, activation = LeakyReLU(alpha=0.2)) (i)\n",
        "  x = Reshape((4,4,256)) (x)\n",
        "\n",
        "  x = Conv2DTranspose(128, (5,5), strides = 4, padding = \"same\", activation = LeakyReLU(alpha=0.2))(x)\n",
        "  x = Conv2DTranspose(128, (5,5), strides = 4, padding = \"same\", activation = LeakyReLU(alpha=0.2))(x)\n",
        "  x = Conv2DTranspose(128, (5,5), strides = 4, padding = \"same\", activation = LeakyReLU(alpha=0.2))(x)\n",
        "  x = Conv2DTranspose(3, (3,3), padding = \"same\", activation = \"tanh\")(x)\n",
        "\n",
        "  model = Model(i,x)\n",
        "  return model"
      ],
      "metadata": {
        "id": "INFDxNlmDll_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "・　Check the output shape in the below summary. It should be (None, 512, 512, 3)."
      ],
      "metadata": {
        "id": "Zx53sod7Gn2g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "generator_check = build_generator(latent_dim)\n",
        "generator_check.summary()"
      ],
      "metadata": {
        "id": "96X_erKiEwRp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "・ Define discriminator. It is a series of convolutional layer to discriminate generator images and training images."
      ],
      "metadata": {
        "id": "dXOo6ZGNGx-z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_discriminator(image_size):\n",
        "  i = Input(shape=image_size)\n",
        "  x = Conv2D(64,(5,5), strides=4, padding = \"same\", activation=LeakyReLU(alpha=0.2))(i)\n",
        "  x = Conv2D(128,(5,5), strides=4, padding = \"same\", activation=LeakyReLU(alpha=0.2))(x)\n",
        "  x = Conv2D(128,(5,5), strides=4, padding = \"same\", activation=LeakyReLU(alpha=0.2))(x)\n",
        "  x = Conv2D(256,(5,5), strides=4, padding = \"same\", activation=LeakyReLU(alpha=0.2))(x)\n",
        "  x = Flatten()(x)\n",
        "  x = Dropout(0.4)(x)\n",
        "  x = Dense(1, activation=\"sigmoid\")(x)\n",
        "\n",
        "  model = Model(i,x)\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "-LamFv-pElnR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "・ Check the output shape in the below summary. It sould be (None, 1)."
      ],
      "metadata": {
        "id": "qE6L4VVWG8MT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "discriminator_check = build_discriminator((512,512,3))\n",
        "discriminator_check.summary()"
      ],
      "metadata": {
        "id": "2HoTxsR3ExQv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "・　Basic set up"
      ],
      "metadata": {
        "id": "ARh2-HUyHae-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 128\n",
        "ones = np.ones(batch_size)\n",
        "zeros = np.zeros(batch_size)\n",
        "\n",
        "d_losses = []\n",
        "g_losses = []\n",
        "\n",
        "if not os.path.exists(\"gan_images\"):\n",
        "  os.makedirs(\"gan_images\")"
      ],
      "metadata": {
        "id": "d4m4BZXoFPZC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "・　below is actual training process. Change the epochs and sample period for your needs."
      ],
      "metadata": {
        "id": "kuRaLJPdHiKX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with strategy.scope():\n",
        "  discriminator = build_discriminator([512,512,3])\n",
        "  discriminator.compile(optimizer = Adam(0.0002, 0.5),\n",
        "                      loss = \"binary_crossentropy\",\n",
        "                      metrics = [\"accuracy\"])\n",
        "\n",
        "  generator = build_generator(latent_dim)\n",
        "\n",
        "  z = Input(shape=(latent_dim,))\n",
        "\n",
        "  img = generator(z)\n",
        "\n",
        "  discriminator.trainable = False\n",
        "\n",
        "  fake_pred = discriminator(img)\n",
        "\n",
        "  combined_model = Model(z, fake_pred)\n",
        "\n",
        "  combined_model.compile(optimizer = Adam(0.0002, 0.5),\n",
        "                       loss = \"binary_crossentropy\")\n",
        "\n",
        "epochs = 10000\n",
        "sample_period = 100\n",
        "\n",
        "for epoch in range(epochs):\n",
        "\n",
        "  ## train discriminator ##\n",
        "\n",
        "  # get random batches of real images\n",
        "  idx = np.random.randint(0, im_array.shape[0], batch_size)\n",
        "  real_imgs = im_array[idx]\n",
        "\n",
        "  # generate fake images\n",
        "  noise = np.random.randn(batch_size, latent_dim)\n",
        "  fake_imgs = generator.predict(noise)\n",
        "\n",
        "  # use train_on_batch to train discriminator\n",
        "  d_loss_real, d_acc_real = discriminator.train_on_batch(real_imgs, ones)\n",
        "  d_loss_fake, d_acc_fake = discriminator.train_on_batch(fake_imgs, zeros)\n",
        "  d_loss = (d_loss_real + d_loss_fake) / 2\n",
        "  d_acc = (d_acc_real + d_acc_fake) / 2\n",
        "\n",
        "  ## train generator ##\n",
        "\n",
        "  # by calling combined model and optimize for the freezed discriminator values to ones\n",
        "  # we can optimize generator to generate real like images\n",
        "  noise = np.random.randn(batch_size, latent_dim)\n",
        "  g_loss = combined_model.train_on_batch(noise, ones)\n",
        "\n",
        "  d_losses.append(d_loss)\n",
        "  g_losses.append(g_loss)\n",
        "\n",
        "  if epoch % 10 == 0:\n",
        "    print(f\"epoch: {epoch+1} / {epochs}, d_loss: {d_loss:.2f}, d_acc: {d_acc:.2f}, g_loss: {g_loss:.2f}\")\n",
        "\n",
        "  if epoch % sample_period == 0:\n",
        "    sample_images(epoch)"
      ],
      "metadata": {
        "id": "9If1fX8WFVEB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "・　after training, same the models and weights. Make sure to download them on your hard drive."
      ],
      "metadata": {
        "id": "8-IzNE79HuXa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "generator.save(\"generator_model.h5\")\n",
        "discriminator.save(\"discriminator_model.h5\")"
      ],
      "metadata": {
        "id": "544d6oTYFogf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generator_weights = generator.get_weights()\n",
        "discriminator_weights = discriminator.get_weights()\n",
        "model_dir = \"model_dir\"\n",
        "if not os.path.exists(model_dir):\n",
        "  os.makedirs(model_dir)\n",
        "np.save(os.path.join(model_dir, 'gan_generator_weights'), generator_weights)\n",
        "np.save(os.path.join(model_dir, 'gan_discriminator_weights'), discriminator_weights)"
      ],
      "metadata": {
        "id": "6sVYOfPeFvO9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "・ Run below when you want the plot of losses of discriminator and generator. "
      ],
      "metadata": {
        "id": "h8DLtXZkIoAJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(d_losses, label = \"d_losses\")\n",
        "plt.plot(g_losses, label = \"g_losses\")\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "ulVXp2UaIm2t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Additional training of your model**"
      ],
      "metadata": {
        "id": "s3OnmuN3H7-D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "When you already have your model and weights trained and want to train your model even more, below is the code you need to run."
      ],
      "metadata": {
        "id": "lGU3KtT1IHvD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "・　Loading in your model and weights. (when you set different name, please reflect changes here too.)"
      ],
      "metadata": {
        "id": "w3N7Oq8CJ-8Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "generator_loaded = tf.keras.models.load_model(\"generator_model.h5\")\n",
        "discriminator_loaded = tf.keras.models.load_model(\"discriminator_model.h5\")"
      ],
      "metadata": {
        "id": "k-SNxkN-IE0a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generator_weights = np.load(\"model_dir/gan_generator_weights.npy\", allow_pickle=True)\n",
        "discriminator_weights = np.load(\"model_dir/gan_discriminator_weights.npy\", allow_pickle=True)"
      ],
      "metadata": {
        "id": "mYsH9aP0ITm8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generator_loaded.set_weights(generator_weights)\n",
        "discriminator_loaded.set_weights(discriminator_weights)"
      ],
      "metadata": {
        "id": "46URknXaIZu4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "・ Check your models"
      ],
      "metadata": {
        "id": "ppX3x_m-JwTv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# generator check\n",
        "noise = np.random.randn(1,latent_dim)\n",
        "img = generator_loaded.predict(noise)\n",
        "img = img * 0.5 + 0.5\n",
        "plt.imshow(img.reshape(512,512,3))"
      ],
      "metadata": {
        "id": "jgYvuL7cIdiI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# discriminator check\n",
        "img = (img-0.5) / 0.5\n",
        "discriminator_loaded.predict(img)"
      ],
      "metadata": {
        "id": "4CMTXZsWJ3m9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "・ Training"
      ],
      "metadata": {
        "id": "bZFXYXntECxR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 128\n",
        "ones = np.ones(batch_size)\n",
        "zeros = np.zeros(batch_size)\n",
        "\n",
        "d_losses = []\n",
        "g_losses = []\n",
        "\n",
        "if not os.path.exists(\"gan_images\"):\n",
        "  os.makedirs(\"gan_images\")"
      ],
      "metadata": {
        "id": "UiiGYT_xEOg1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with strategy.scope():\n",
        "  discriminator_loaded.compile(optimizer = Adam(0.0002, 0.5),\n",
        "                      loss = \"binary_crossentropy\",\n",
        "                      metrics = [\"accuracy\"])\n",
        "\n",
        "  z = Input(shape=(latent_dim,))\n",
        "\n",
        "  img = generator_loaded(z)\n",
        "\n",
        "  discriminator_loaded.trainable = False\n",
        "\n",
        "  fake_pred = discriminator_loaded(img)\n",
        "\n",
        "  combined_model = Model(z, fake_pred)\n",
        "\n",
        "  combined_model.compile(optimizer = Adam(0.0002, 0.5),\n",
        "                       loss = \"binary_crossentropy\")\n",
        "\n",
        "batch_size = 128\n",
        "epochs = 10000\n",
        "sample_period = 100\n",
        "\n",
        "for epoch in range(epochs):\n",
        "\n",
        "  ## train discriminator ##\n",
        "\n",
        "  # get random batches of real images\n",
        "  idx = np.random.randint(0, im_array.shape[0], batch_size)\n",
        "  real_imgs = im_array[idx]\n",
        "\n",
        "  # generate fake images\n",
        "  noise = np.random.randn(batch_size, latent_dim)\n",
        "  fake_imgs = generator_loaded.predict(noise)\n",
        "\n",
        "  # use train_on_batch to train discriminator\n",
        "  d_loss_real, d_acc_real = discriminator_loaded.train_on_batch(real_imgs, ones)\n",
        "  d_loss_fake, d_acc_fake = discriminator_loaded.train_on_batch(fake_imgs, zeros)\n",
        "  d_loss = (d_loss_real + d_loss_fake) / 2\n",
        "  d_acc = (d_acc_real + d_acc_fake) / 2\n",
        "\n",
        "  ## train generator ##\n",
        "\n",
        "  # by calling combined model and optimize for the freezed discriminator values to ones\n",
        "  # we can optimize generator to generate real like images\n",
        "  noise = np.random.randn(batch_size, latent_dim)\n",
        "  g_loss = combined_model.train_on_batch(noise, ones)\n",
        "\n",
        "  d_losses.append(d_loss)\n",
        "  g_losses.append(g_loss)\n",
        "\n",
        "  if epoch % 10 == 0:\n",
        "    print(f\"epoch: {epoch+1} / {epochs}, d_loss: {d_loss:.2f}, d_acc: {d_acc:.2f}, g_loss: {g_loss:.2f}\")\n",
        "\n",
        "  if epoch % sample_period == 0:\n",
        "    sample_images(epoch)"
      ],
      "metadata": {
        "id": "eCZzDr3gJ9ZF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "・　after training, same the models and weights. Make sure to download them on your hard drive."
      ],
      "metadata": {
        "id": "VnqLgOMyLciw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "generator_loaded.save(\"generator_model.h5\")\n",
        "discriminator_loaded.save(\"discriminator_model.h5\")"
      ],
      "metadata": {
        "id": "_kP8PA4NLdIJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generator_weights = generator_loaded.get_weights()\n",
        "discriminator_weights = discriminator_loaded.get_weights()\n",
        "model_dir = \"model_dir\"\n",
        "if not os.path.exists(model_dir):\n",
        "  os.makedirs(model_dir)\n",
        "np.save(os.path.join(model_dir, 'gan_generator_weights'), generator_weights)\n",
        "np.save(os.path.join(model_dir, 'gan_discriminator_weights'), discriminator_weights)"
      ],
      "metadata": {
        "id": "ovZf-b_HLgJ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "・ Run below when you want the plot of losses of discriminator and generator. "
      ],
      "metadata": {
        "id": "mdsdqXPeL0Pg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(d_losses, label = \"d_losses\")\n",
        "plt.plot(g_losses, label = \"g_losses\")\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "sGesY0c9L0sP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **TF Lite file for mobile app**"
      ],
      "metadata": {
        "id": "bXQA8d2IeN3y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "・ If you have saved the trained model and haven't done additional training, run below"
      ],
      "metadata": {
        "id": "Y7o15kOTGLW3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "generator_loaded = tf.keras.models.load_model(\"generator_model.h5\")\n",
        "generator_weights = np.load(\"model_dir/gan_generator_weights.npy\", allow_pickle=True)\n",
        "\n",
        "generator_loaded.set_weights(generator_weights)"
      ],
      "metadata": {
        "id": "u7AvDsk9GM98"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "・　Below convert the model into tflite file which can be used for mobile app development"
      ],
      "metadata": {
        "id": "EfYRy6XyGZ7u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(generator_loaded) ## change the name according to the current name of the generator\n",
        "\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "with open(\"generator_model.tflite\", \"wb\") as f:\n",
        "  f.write(tfile_model)"
      ],
      "metadata": {
        "id": "Lsv06r7qeNNm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}